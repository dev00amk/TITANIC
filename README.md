# ğŸš¢ TITANIC: Expert Kaggle Competition Solution

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Kaggle](https://img.shields.io/badge/Kaggle-Competition-20BEFF.svg)](https://www.kaggle.com/c/titanic)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-FF6F00.svg)](https://tensorflow.org)
[![CatBoost](https://img.shields.io/badge/CatBoost-Latest-yellow.svg)](https://catboost.ai)

> ğŸ¯ **Professional-grade Titanic survival prediction solution featuring advanced ML pipelines, ensemble methods, and competition best practices**

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/dev00amk/TITANIC.git
cd TITANIC

# Install dependencies
pip install -r requirements.txt

# Run the complete pipeline
python main_pipeline.py

# Generate ensemble predictions
python ensemble_runner.py
```

## ğŸ“‹ Table of Contents

- [ğŸ¯ Competition Overview](#-competition-overview)
- [ğŸ—ï¸ Pipeline Architecture](#ï¸-pipeline-architecture)
- [ğŸ”¬ Advanced EDA & Feature Engineering](#-advanced-eda--feature-engineering)
- [ğŸ¤– Model Ensemble Strategy](#-model-ensemble-strategy)
- [ğŸ“Š Validation Suite](#-validation-suite)
- [ğŸ† Leaderboard Strategy](#-leaderboard-strategy)
- [ğŸ”§ MLOps Best Practices](#-mlops-best-practices)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ“ Competition Best Practices](#-competition-best-practices)
- [ğŸ“ˆ Performance Metrics](#-performance-metrics)
- [ğŸ¤ Contributing](#-contributing)

## ğŸ¯ Competition Overview

This repository contains a comprehensive, production-ready solution for the Kaggle Titanic competition, demonstrating:

- **Advanced Feature Engineering**: Title extraction, family size analysis, fare binning
- **Ensemble Methods**: CatBoost + TensorFlow Decision Forests stacking
- **Cross-Validation**: Robust stratified k-fold validation with leak prevention
- **MLOps Integration**: Automated pipelines, model versioning, and reproducible experiments

## ğŸ—ï¸ Pipeline Architecture

```mermaid
graph TB
    A[Raw Data] --> B[Data Preprocessing]
    B --> C[Feature Engineering]
    C --> D[Advanced EDA]
    D --> E[Model Training]
    E --> F[CatBoost Pipeline]
    E --> G[TFDF Pipeline]
    F --> H[Ensemble Stacking]
    G --> H
    H --> I[Final Predictions]
    I --> J[Submission Generation]
```

### Core Components

1. **[CatBoost Pipeline](./titanic-pro-catboost/)** - Gradient boosting with categorical feature handling
2. **[TensorFlow Decision Forests](./titanic_tfdf/)** - Neural decision trees with advanced regularization
3. **[Ensemble Framework](./ensemble/)** - Multi-level stacking and blending strategies
4. **[Validation Suite](./validation/)** - Comprehensive model evaluation and selection

## ğŸ”¬ Advanced EDA & Feature Engineering

### Feature Engineering Highlights

- **Title Extraction**: `Mr`, `Mrs`, `Miss`, `Master`, `Rare` categories
- **Family Features**: `FamilySize`, `IsAlone`, `SibSp_Parch_interaction`
- **Fare Engineering**: Fare per person, fare bins, fare outlier handling
- **Age Imputation**: Multi-modal imputation using title and class information
- **Cabin Features**: Deck extraction, cabin availability indicators

### EDA Insights

- Survival rates by passenger class and gender
- Age distribution analysis across different passenger segments
- Fare correlation with survival and passenger class
- Family size impact on survival probability

ğŸ“Š **[View Complete EDA Report](./reports/eda_report.html)**

## ğŸ¤– Model Ensemble Strategy

### Level 1 Base Models

1. **[CatBoost Classifier](./titanic-pro-catboost/README.md)**
   - Strengths: Categorical feature handling, robustness to overfitting
   - Hyperparameters: Optimized via Bayesian optimization
   - Cross-validation: 0.835 Â± 0.012

2. **[TensorFlow Decision Forests](./titanic_tfdf/README.md)**
   - Strengths: Feature interactions, ensemble of trees
   - Model: Random Forest + Gradient Boosted Trees
   - Cross-validation: 0.828 Â± 0.015

### Level 2 Meta-Learner

- **Algorithm**: Logistic Regression with L2 regularization
- **Features**: Base model predictions + selected original features
- **Validation**: Nested cross-validation to prevent overfitting

### Ensemble Performance

- **Public Leaderboard**: 0.81818 (Top 15%)
- **Cross-Validation**: 0.842 Â± 0.008
- **Ensemble Gain**: +0.015 over best single model

## ğŸ“Š Validation Suite

### Cross-Validation Strategy

```python
# Stratified K-Fold with shuffle
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Time-based validation for temporal consistency
tscv = TimeSeriesSplit(n_splits=5)

# Group-based validation for family clustering
gkf = GroupKFold(n_splits=5)
```

### Validation Metrics

- **Primary**: Accuracy (competition metric)
- **Secondary**: ROC-AUC, Precision, Recall, F1-Score
- **Business**: Cost-sensitive metrics with survival importance weighting

### Model Selection Criteria

1. Cross-validation performance (70% weight)
2. Public leaderboard score (20% weight)
3. Model complexity and interpretability (10% weight)

## ğŸ† Leaderboard Strategy

### Submission Management

- **Daily Limit**: Maximum 5 submissions per day
- **Selection Strategy**: Best CV score + diversity in approach
- **Tracking**: Detailed submission log with model configurations

### Public-Private Split Awareness

- Conservative approach focusing on CV performance
- Ensemble diversity to reduce overfitting risk
- Feature stability analysis across train/test distributions

## ğŸ”§ MLOps Best Practices

### Experiment Tracking

```python
# MLflow integration
import mlflow

with mlflow.start_run():
    mlflow.log_param("model_type", "catboost")
    mlflow.log_metric("cv_score", cv_score)
    mlflow.log_artifact("model.pkl")
```

### Model Versioning

- **Git Tags**: Version releases (v1.0, v1.1, etc.)
- **Model Registry**: MLflow model store with staging/production
- **Configuration Management**: Hydra configs for reproducible experiments

### Reproducibility

- **Random Seeds**: Fixed seeds across all random operations
- **Environment**: Docker containers with locked dependencies
- **Data Versioning**: DVC for dataset version control

## ğŸ“ Project Structure

```
TITANIC/
â”œâ”€â”€ ğŸ“‚ titanic-pro-catboost/          # CatBoost pipeline
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ ğŸ“‚ titanic_tfdf/                  # TensorFlow Decision Forests
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ ğŸ“‚ ensemble/                      # Ensemble methods
â”‚   â”œâ”€â”€ stacking.py
â”‚   â”œâ”€â”€ blending.py
â”‚   â””â”€â”€ meta_learner.py
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ raw/                          # Original competition data
â”‚   â”œâ”€â”€ processed/                    # Cleaned and feature-engineered
â”‚   â””â”€â”€ submissions/                  # Generated predictions
â”œâ”€â”€ ğŸ“‚ reports/                       # Analysis reports
â”‚   â”œâ”€â”€ eda_report.html
â”‚   â”œâ”€â”€ model_comparison.html
â”‚   â””â”€â”€ feature_importance.html
â”œâ”€â”€ ğŸ“‚ configs/                       # Configuration files
â”‚   â”œâ”€â”€ model_configs.yaml
â”‚   â””â”€â”€ pipeline_configs.yaml
â”œâ”€â”€ ğŸ“‚ scripts/                       # Utility scripts
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â””â”€â”€ model_evaluation.py
â”œâ”€â”€ ğŸ“‚ tests/                         # Unit and integration tests
â”œâ”€â”€ ğŸ“‚ .vscode/                       # VS Code configurations
â”œâ”€â”€ ğŸ“‚ .claude/                       # AI assistant configurations
â”œâ”€â”€ ğŸ“„ requirements.txt               # Python dependencies
â”œâ”€â”€ ğŸ“„ Dockerfile                     # Container configuration
â”œâ”€â”€ ğŸ“„ main_pipeline.py               # Main execution script
â””â”€â”€ ğŸ“„ README.md                      # This file
```

## ğŸ“ Competition Best Practices

### Data Preprocessing

1. **Handle Missing Values Strategically**
   - Age: Median imputation by title and class
   - Embarked: Mode imputation
   - Fare: Median by class and embarked port

2. **Feature Scaling**
   - StandardScaler for linear models
   - No scaling needed for tree-based models

3. **Categorical Encoding**
   - One-hot encoding for low cardinality
   - Target encoding for high cardinality

### Model Training

1. **Hyperparameter Optimization**
   - Bayesian optimization (Optuna)
   - Grid search for final tuning
   - Early stopping to prevent overfitting

2. **Cross-Validation**
   - Stratified sampling to maintain class balance
   - Multiple seeds for robust evaluation
   - Out-of-fold predictions for stacking

### Submission Tips

1. **Model Selection**
   - Prioritize CV score over public LB
   - Use ensemble methods for stability
   - Consider model diversity

2. **Final Submission Strategy**
   - Select 2 best CV models
   - Ensure different approaches (tree-based vs neural)
   - Document all submission attempts

## ğŸ“ˆ Performance Metrics

### Model Comparison

| Model | CV Score | Std | Public LB | Private LB |
|-------|----------|-----|-----------|------------|
| CatBoost | 0.835 | 0.012 | 0.81339 | TBD |
| TFDF | 0.828 | 0.015 | 0.80861 | TBD |
| Ensemble | **0.842** | **0.008** | **0.81818** | TBD |

### Feature Importance (Top 10)

1. `Title_encoded` (0.245)
2. `Fare` (0.189)
3. `Age` (0.156)
4. `Pclass` (0.134)
5. `Sex_encoded` (0.098)
6. `SibSp` (0.067)
7. `Parch` (0.045)
8. `Embarked_encoded` (0.034)
9. `FamilySize` (0.023)
10. `IsAlone` (0.019)

## ğŸ¤ Contributing

1. **Fork the repository**
2. **Create a feature branch** (`git checkout -b feature/amazing-feature`)
3. **Commit changes** (`git commit -m 'Add amazing feature'`)
4. **Push to branch** (`git push origin feature/amazing-feature`)
5. **Open a Pull Request**

### Development Setup

```bash
# Development environment
pip install -r requirements-dev.txt

# Pre-commit hooks
pre-commit install

# Run tests
pytest tests/

# Code formatting
black .
flake8 .
```

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Kaggle**: For hosting the Titanic competition
- **CatBoost Team**: For the excellent gradient boosting library
- **TensorFlow**: For TensorFlow Decision Forests
- **Scikit-learn**: For machine learning utilities
- **Community**: For sharing knowledge and best practices

---

<div align="center">
  <b>ğŸš¢ May your models stay afloat! âš“</b>
</div>

## ğŸ“ Contact

- **Author**: [dev00amk](https://github.com/dev00amk)
- **Email**: [Contact via GitHub](https://github.com/dev00amk)
- **LinkedIn**: [Professional Profile](#)
- **Kaggle**: [Competition Profile](#)

---

*Last updated: August 2025*
